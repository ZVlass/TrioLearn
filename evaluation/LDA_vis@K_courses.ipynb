{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89153e1d",
   "metadata": {},
   "source": [
    "### LDA with multiple topic counts (6, 10, 15)\n",
    "\n",
    "This script tries multiple topic counts (6, 10, 15), saves a bar chart PNG for each count (to outputs/reports/images/), prints top words per topic (so we can label bars in the report), reports LDA perplexity for quick comparison, handles empty/missing descriptions safely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "015b9250",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cb04b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[check] Using: c:\\Users\\jvlas\\source\\repos\\TrioLearn\\backend\\data\\interim\\courses_metadata_clean.csv\n",
      "[check] Using: c:\\Users\\jvlas\\source\\repos\\TrioLearn\\backend\\data\\interim\\videos_metadata_clean.csv\n",
      "[check] Using: c:\\Users\\jvlas\\source\\repos\\TrioLearn\\backend\\data\\interim\\books_metadata.csv\n"
     ]
    }
   ],
   "source": [
    "# ---------- paths ----------\n",
    "try:\n",
    "    BASE = Path(__file__).resolve().parents[2]   # when in a .py under outputs/reports/\n",
    "except NameError:\n",
    "    BASE = Path.cwd()\n",
    "    if BASE.name == \"reports\":\n",
    "        BASE = BASE.parents[1]\n",
    "    elif BASE.name == \"outputs\":\n",
    "        BASE = BASE.parent\n",
    "\n",
    "courses_path = BASE / \"backend\" / \"data\" / \"interim\" / \"courses_metadata_clean.csv\"\n",
    "videos_path = BASE / \"backend\" / \"data\" / \"interim\" / \"videos_metadata_clean.csv\"\n",
    "books_path = BASE / \"backend\" / \"data\" / \"interim\" / \"books_metadata.csv\"\n",
    "\n",
    "img_dir      = BASE / \"outputs\" / \"reports\" / \"images\"\n",
    "img_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "print(\"[check] Using:\", courses_path)\n",
    "print(\"[check] Using:\", videos_path)\n",
    "print(\"[check] Using:\", books_path)\n",
    "\n",
    "df = pd.read_csv(courses_path)\n",
    "\n",
    "TEXT_COL = \"description\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed4abb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fit_lda_on_masked(df, text_col, n_topics, random_state=42):\n",
    "    txt = df[text_col].astype(str).fillna(\"\").str.strip()\n",
    "    mask = txt.str.len() > 0\n",
    "    texts = txt[mask]\n",
    "    if texts.empty:\n",
    "        raise ValueError(f\"No non-empty docs in '{text_col}'\")\n",
    "\n",
    "    vec = CountVectorizer(stop_words=\"english\", max_df=0.95, min_df=2)\n",
    "    X = vec.fit_transform(texts)\n",
    "    if X.shape[1] == 0:\n",
    "        vec = CountVectorizer(stop_words=\"english\", max_df=1.0, min_df=1)\n",
    "        X = vec.fit_transform(texts)\n",
    "\n",
    "    lda = LatentDirichletAllocation(\n",
    "        n_components=n_topics, learning_method=\"batch\", random_state=random_state\n",
    "    )\n",
    "    theta = lda.fit_transform(X)  # rows align to texts.index\n",
    "    dom = pd.Series(theta.argmax(axis=1), index=texts.index)\n",
    "\n",
    "    # attach \n",
    "    col = f\"dom_topic_{n_topics}\"\n",
    "    out = df.copy()\n",
    "    out[col] = np.nan\n",
    "    out.loc[mask, col] = dom\n",
    "    return out, lda, vec, X, col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dff0a924",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_words_per_topic(lda, vectorizer, topn=10):\n",
    "    terms = np.array(vectorizer.get_feature_names_out())\n",
    "    tops = []\n",
    "    for k, comp in enumerate(lda.components_):\n",
    "        idx = np.argsort(comp)[::-1][:topn]\n",
    "        words = terms[idx]\n",
    "        tops.append((k, words))\n",
    "    return tops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60ac1f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_distribution_plot(df, topic_col, n_topics, out_png_path, title_prefix=\"Courses\"):\n",
    "    counts = pd.Series(pd.Categorical(df[topic_col], categories=range(n_topics))).value_counts().sort_index()\n",
    "    plt.figure(figsize=(10,5))\n",
    "    counts.plot(kind=\"bar\")\n",
    "    plt.title(f\"Distribution of Dominant Topics ({title_prefix}) â€” K={n_topics}\")\n",
    "    plt.xlabel(\"Topic\")\n",
    "    plt.ylabel(\"Number of Items\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_png_path, dpi=300)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e434506",
   "metadata": {},
   "source": [
    "### Run script for COURSES with several K = 6, 10, 15. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4388da37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fitting LDA with K=6 ===\n",
      "[metric] Perplexity(K=6): 1,165.97\n",
      "[topics] Top words per topic (K=6):\n",
      "  Topic 0: en, google, la, des, les, et, que, para, vous, el\n",
      "  Topic 1: nan, project, management, ll, program, skills, projects, software, cloud, development\n",
      "  Topic 2: data, learning, course, specialization, ll, machine, project, skills, learn, ai\n",
      "  Topic 3: cloud, google, exam, professional, learning, certification, hands, aws, microsoft, new\n",
      "  Topic 4: data, course, skills, ll, learn, business, project, analytics, program, career\n",
      "  Topic 5: course, design, specialization, financial, ux, business, learn, new, understand, project\n",
      "[save] c:\\Users\\jvlas\\source\\repos\\TrioLearn\\outputs\\reports\\images\\courses_topic_distribution_K6.png\n",
      "\n",
      "=== Fitting LDA with K=10 ===\n",
      "[metric] Perplexity(K=10): 1,194.22\n",
      "[topics] Top words per topic (K=10):\n",
      "  Topic 0: des, google, les, et, learning, vous, la, machine, une, en\n",
      "  Topic 1: project, ll, skills, management, software, projects, program, cloud, development, devops\n",
      "  Topic 2: data, learning, specialization, project, course, machine, ai, cybersecurity, learn, skills\n",
      "  Topic 3: cloud, google, professional, exam, new, certification, hands, tab, qwiklabs, learning\n",
      "  Topic 4: business, skills, ll, course, learn, new, career, google, program, marketing\n",
      "  Topic 5: course, specialization, learning, new, learn, product, understand, business, gans, accounting\n",
      "  Topic 6: design, create, ll, ux, end, program, project, learn, using, course\n",
      "  Topic 7: data, course, analysis, analytics, skills, science, use, using, specialization, business\n",
      "  Topic 8: course, project, learn, management, health, understand, cloud, team, provide, use\n",
      "  Topic 9: nan, en, data, el, que, para, sql, la, las, los\n",
      "[save] c:\\Users\\jvlas\\source\\repos\\TrioLearn\\outputs\\reports\\images\\courses_topic_distribution_K10.png\n",
      "\n",
      "=== Fitting LDA with K=15 ===\n",
      "[metric] Perplexity(K=15): 1,215.46\n",
      "[topics] Top words per topic (K=15):\n",
      "  Topic 0: des, les, et, la, vous, google, une, en, gestion, projet\n",
      "  Topic 1: project, ll, management, program, skills, career, projects, job, help, designed\n",
      "  Topic 2: data, course, skills, specialization, cybersecurity, project, python, ll, science, learn\n",
      "  Topic 3: course, finance, make, word, financial, models, exam, decisions, help, capital\n",
      "  Topic 4: business, course, skills, learn, new, marketing, google, data, ll, courses\n",
      "  Topic 5: course, product, specialization, new, learn, gans, learning, business, google, www\n",
      "  Topic 6: design, create, ux, ll, program, learn, end, project, course, using\n",
      "  Topic 7: course, data, supply, chain, specialization, engineering, production, english, skills, analytics\n",
      "  Topic 8: course, project, management, learn, team, manage, use, agile, human, understand\n",
      "  Topic 9: data, en, sql, que, para, el, analysis, las, use, skills\n",
      "  Topic 10: projects, cloud, using, programming, ll, python, software, end, learning, skills\n",
      "  Topic 11: cloud, google, hands, exam, professional, certification, aws, new, tab, skills\n",
      "  Topic 12: nan, data, course, learn, ll, analytics, business, financial, analyst, analysis\n",
      "  Topic 13: specialization, data, learning, courses, learners, science, course, financial, concepts, project\n",
      "  Topic 14: learning, ai, machine, specialization, course, build, data, health, use, deep\n",
      "[save] c:\\Users\\jvlas\\source\\repos\\TrioLearn\\outputs\\reports\\images\\courses_topic_distribution_K15.png\n",
      "\n",
      "[summary]\n",
      "  K=6: perplexity=1165.97 | plot=c:\\Users\\jvlas\\source\\repos\\TrioLearn\\outputs\\reports\\images\\courses_topic_distribution_K6.png\n",
      "  K=10: perplexity=1194.22 | plot=c:\\Users\\jvlas\\source\\repos\\TrioLearn\\outputs\\reports\\images\\courses_topic_distribution_K10.png\n",
      "  K=15: perplexity=1215.46 | plot=c:\\Users\\jvlas\\source\\repos\\TrioLearn\\outputs\\reports\\images\\courses_topic_distribution_K15.png\n"
     ]
    }
   ],
   "source": [
    "\n",
    "topic_grid = [6, 10, 15]  \n",
    "results = []\n",
    "\n",
    "for K in topic_grid:\n",
    "    print(f\"\\n=== Fitting LDA with K={K} ===\")\n",
    "    dfK, ldaK, vecK, XK, colK = fit_lda_on_masked(df, TEXT_COL, n_topics=K, random_state=42)\n",
    "\n",
    "    # perplexity (lower is better)\n",
    "    perp = ldaK.perplexity(XK)\n",
    "    print(f\"[metric] Perplexity(K={K}): {perp:,.2f}\")\n",
    "\n",
    "    # top words\n",
    "    print(f\"[topics] Top words per topic (K={K}):\")\n",
    "    for k, words in top_words_per_topic(ldaK, vecK, topn=10):\n",
    "        print(f\"  Topic {k}: {', '.join(words)}\")\n",
    "\n",
    "    # save plot\n",
    "    png_path = img_dir / f\"Courses_topic_distribution_K{K}.png\"\n",
    "    save_distribution_plot(dfK, colK, n_topics=K, out_png_path=png_path, title_prefix=\"Courses\")\n",
    "    print(f\"[save] {png_path}\")\n",
    "\n",
    "    results.append({\"K\": K, \"perplexity\": perp, \"png\": str(png_path), \"topic_col\": colK})\n",
    "\n",
    "print(\"\\n[summary]\")\n",
    "for r in results:\n",
    "    print(f\"  K={r['K']}: perplexity={r['perplexity']:.2f} | plot={r['png']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e440c8c",
   "metadata": {},
   "source": [
    "### Run script for videos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7f401b",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_grid = [6, 10, 15] \n",
    "results = []\n",
    "\n",
    "for K in topic_grid:\n",
    "    print(f\"\\n=== Fitting LDA with K={K} ===\")\n",
    "    dfK, ldaK, vecK, XK, colK = fit_lda_on_masked(df, TEXT_COL, n_topics=K, random_state=42)\n",
    "\n",
    "    # perplexity (lower is better)\n",
    "    perp = ldaK.perplexity(XK)\n",
    "    print(f\"[metric] Perplexity(K={K}): {perp:,.2f}\")\n",
    "\n",
    "    # top words\n",
    "    print(f\"[topics] Top words per topic (K={K}):\")\n",
    "    for k, words in top_words_per_topic(ldaK, vecK, topn=10):\n",
    "        print(f\"  Topic {k}: {', '.join(words)}\")\n",
    "\n",
    "    # save plot\n",
    "    png_path = img_dir / f\"videos_topic_distribution_K{K}.png\"\n",
    "    save_distribution_plot(dfK, colK, n_topics=K, out_png_path=png_path, title_prefix=\"Videos\")\n",
    "    print(f\"[save] {png_path}\")\n",
    "\n",
    "    results.append({\"K\": K, \"perplexity\": perp, \"png\": str(png_path), \"topic_col\": colK})\n",
    "\n",
    "print(\"\\n[summary]\")\n",
    "for r in results:\n",
    "    print(f\"  K={r['K']}: perplexity={r['perplexity']:.2f} | plot={r['png']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
