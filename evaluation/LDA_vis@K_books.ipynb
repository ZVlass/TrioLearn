{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89153e1d",
   "metadata": {},
   "source": [
    "### LDA with multiple topic counts (6, 10, 15) for BOOKS\n",
    "\n",
    "This script tries multiple topic counts (6, 10, 15), saves a bar chart PNG for each count (to outputs/reports/images/), prints top words per topic (so we can label bars in the report), reports LDA perplexity for quick comparison, handles empty/missing descriptions safely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "015b9250",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14cb04b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[check] Using: c:\\Users\\jvlas\\source\\repos\\TrioLearn\\backend\\data\\interim\\books_metadata.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "try:\n",
    "    BASE = Path(__file__).resolve().parents[2]   # when in a .py under outputs/reports/\n",
    "except NameError:\n",
    "    BASE = Path.cwd()\n",
    "    if BASE.name == \"reports\":\n",
    "        BASE = BASE.parents[1]\n",
    "    elif BASE.name == \"outputs\":\n",
    "        BASE = BASE.parent\n",
    "\n",
    "\n",
    "books_path = BASE / \"backend\" / \"data\" / \"interim\" / \"books_metadata.csv\"\n",
    "\n",
    "img_dir      = BASE / \"outputs\" / \"reports\" / \"images\"\n",
    "img_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "print(\"[check] Using:\", books_path)\n",
    "\n",
    "df = pd.read_csv(books_path)\n",
    "\n",
    "TEXT_COL = \"description\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ed4abb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fit_lda_on_masked(df, text_col, n_topics, random_state=42):\n",
    "    txt = df[text_col].astype(str).fillna(\"\").str.strip()\n",
    "    mask = txt.str.len() > 0\n",
    "    texts = txt[mask]\n",
    "    if texts.empty:\n",
    "        raise ValueError(f\"No non-empty docs in '{text_col}'\")\n",
    "\n",
    "    vec = CountVectorizer(stop_words=\"english\", max_df=0.95, min_df=2)\n",
    "    X = vec.fit_transform(texts)\n",
    "    if X.shape[1] == 0:\n",
    "        vec = CountVectorizer(stop_words=\"english\", max_df=1.0, min_df=1)\n",
    "        X = vec.fit_transform(texts)\n",
    "\n",
    "    lda = LatentDirichletAllocation(\n",
    "        n_components=n_topics, learning_method=\"batch\", random_state=random_state\n",
    "    )\n",
    "    theta = lda.fit_transform(X)  # rows align to texts.index\n",
    "    dom = pd.Series(theta.argmax(axis=1), index=texts.index)\n",
    "\n",
    "    # attach \n",
    "    col = f\"dom_topic_{n_topics}\"\n",
    "    out = df.copy()\n",
    "    out[col] = np.nan\n",
    "    out.loc[mask, col] = dom\n",
    "    return out, lda, vec, X, col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dff0a924",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_words_per_topic(lda, vectorizer, topn=10):\n",
    "    terms = np.array(vectorizer.get_feature_names_out())\n",
    "    tops = []\n",
    "    for k, comp in enumerate(lda.components_):\n",
    "        idx = np.argsort(comp)[::-1][:topn]\n",
    "        words = terms[idx]\n",
    "        tops.append((k, words))\n",
    "    return tops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ac1f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_distribution_plot(df, topic_col, n_topics, out_png_path, title_prefix=\"Books\"):\n",
    "    counts = pd.Series(pd.Categorical(df[topic_col], categories=range(n_topics))).value_counts().sort_index()\n",
    "    plt.figure(figsize=(10,5))\n",
    "    counts.plot(kind=\"bar\")\n",
    "    plt.title(f\"Distribution of Dominant Topics ({title_prefix}) â€” K={n_topics}\")\n",
    "    plt.xlabel(\"Topic\")\n",
    "    plt.ylabel(\"Number of Items\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_png_path, dpi=300)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e434506",
   "metadata": {},
   "source": [
    "### Run script for books with several K = 6, 10, 15. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4388da37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fitting LDA with K=6 ===\n",
      "[metric] Perplexity(K=6): 1,560.14\n",
      "[topics] Top words per topic (K=6):\n",
      "  Topic 0: data, python, docker, book, learn, sql, science, use, using, visualization\n",
      "  Topic 1: programming, web, book, java, python, development, learn, applications, language, using\n",
      "  Topic 2: computer, vision, python, image, processing, book, recognition, opencv, chapter, robotics\n",
      "  Topic 3: cloud, ai, security, book, computing, sql, cybersecurity, ethical, cyber, server\n",
      "  Topic 4: learning, deep, machine, neural, book, networks, language, models, processing, nlp\n",
      "  Topic 5: book, data, research, science, systems, applications, design, information, engineering, students\n",
      "[save] c:\\Users\\jvlas\\source\\repos\\TrioLearn\\outputs\\reports\\images\\Books_topic_distribution_K6.png\n",
      "\n",
      "=== Fitting LDA with K=10 ===\n",
      "[metric] Perplexity(K=10): 1,506.38\n",
      "[topics] Top words per topic (K=10):\n",
      "  Topic 0: data, visualization, book, business, use, tools, learn, using, information, analysis\n",
      "  Topic 1: web, development, book, applications, design, build, using, learn, ll, application\n",
      "  Topic 2: python, programming, book, learn, language, data, learning, code, coding, guide\n",
      "  Topic 3: ai, cloud, computing, book, security, ethical, cybersecurity, cyber, technology, technologies\n",
      "  Topic 4: learning, deep, machine, book, neural, language, networks, models, processing, nlp\n",
      "  Topic 5: data, science, book, papers, learning, conference, research, analysis, analytics, machine\n",
      "  Topic 6: book, chapter, neural, concepts, networks, programming, examples, students, problems, design\n",
      "  Topic 7: computer, systems, applications, research, book, vision, software, design, engineering, image\n",
      "  Topic 8: java, programming, learn, book, language, step, guide, need, time, know\n",
      "  Topic 9: sql, docker, database, book, server, using, learn, use, containers, data\n",
      "[save] c:\\Users\\jvlas\\source\\repos\\TrioLearn\\outputs\\reports\\images\\Books_topic_distribution_K10.png\n",
      "\n",
      "=== Fitting LDA with K=15 ===\n",
      "[metric] Perplexity(K=15): 1,504.35\n",
      "[topics] Top words per topic (K=15):\n",
      "  Topic 0: papers, conference, information, international, held, proceedings, selected, book, healthcare, management\n",
      "  Topic 1: web, development, design, book, software, applications, build, javascript, ll, html\n",
      "  Topic 2: university, computer, professor, dr, robotics, india, engineering, science, department, research\n",
      "  Topic 3: cloud, computing, book, services, business, service, security, azure, technologies, technology\n",
      "  Topic 4: learning, deep, machine, language, processing, book, natural, models, nlp, nan\n",
      "  Topic 5: data, science, book, analysis, learning, analytics, machine, statistical, big, techniques\n",
      "  Topic 6: neural, networks, book, algorithms, network, learning, problems, models, deep, theory\n",
      "  Topic 7: systems, computer, book, research, applications, software, researchers, engineering, vision, students\n",
      "  Topic 8: security, cybersecurity, cyber, threats, book, digital, policy, risk, attacks, law\n",
      "  Topic 9: docker, containers, exam, security, container, book, learn, linux, applications, guide\n",
      "  Topic 10: python, programming, learn, book, language, learning, guide, step, code, coding\n",
      "  Topic 11: ai, book, ethical, intelligence, data, artificial, ethics, visualization, world, challenges\n",
      "  Topic 12: sql, java, database, data, book, server, programming, use, using, learn\n",
      "  Topic 13: book, using, data, python, ll, learn, applications, use, build, processing\n",
      "  Topic 14: microservices, spring, native, applications, cloud, boot, using, apis, book, api\n",
      "[save] c:\\Users\\jvlas\\source\\repos\\TrioLearn\\outputs\\reports\\images\\Books_topic_distribution_K15.png\n",
      "\n",
      "[summary]\n",
      "  K=6: perplexity=1560.14 | plot=c:\\Users\\jvlas\\source\\repos\\TrioLearn\\outputs\\reports\\images\\Books_topic_distribution_K6.png\n",
      "  K=10: perplexity=1506.38 | plot=c:\\Users\\jvlas\\source\\repos\\TrioLearn\\outputs\\reports\\images\\Books_topic_distribution_K10.png\n",
      "  K=15: perplexity=1504.35 | plot=c:\\Users\\jvlas\\source\\repos\\TrioLearn\\outputs\\reports\\images\\Books_topic_distribution_K15.png\n"
     ]
    }
   ],
   "source": [
    "\n",
    "topic_grid = [6, 10, 15]  \n",
    "results = []\n",
    "\n",
    "for K in topic_grid:\n",
    "    print(f\"\\n=== Fitting LDA with K={K} ===\")\n",
    "    dfK, ldaK, vecK, XK, colK = fit_lda_on_masked(df, TEXT_COL, n_topics=K, random_state=42)\n",
    "\n",
    "    # perplexity (lower is better)\n",
    "    perp = ldaK.perplexity(XK)\n",
    "    print(f\"[metric] Perplexity(K={K}): {perp:,.2f}\")\n",
    "\n",
    "    # top words\n",
    "    print(f\"[topics] Top words per topic (K={K}):\")\n",
    "    for k, words in top_words_per_topic(ldaK, vecK, topn=10):\n",
    "        print(f\"  Topic {k}: {', '.join(words)}\")\n",
    "\n",
    "    # save plot\n",
    "    png_path = img_dir / f\"Books_topic_distribution_K{K}.png\"\n",
    "    save_distribution_plot(dfK, colK, n_topics=K, out_png_path=png_path, title_prefix=\"Books\")\n",
    "    print(f\"[save] {png_path}\")\n",
    "\n",
    "    results.append({\"K\": K, \"perplexity\": perp, \"png\": str(png_path), \"topic_col\": colK})\n",
    "\n",
    "print(\"\\n[summary]\")\n",
    "for r in results:\n",
    "    print(f\"  K={r['K']}: perplexity={r['perplexity']:.2f} | plot={r['png']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7f401b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
