{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ff0531b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[meta] rows: 3507\n",
      "[meta] columns: ['keyword', 'volume_id', 'title', 'authors', 'description', 'categories', 'publishedDate', 'pageCount', 'language', 'averageRating', 'ratingsCount', 'previewLink', 'infoLink', 'isbn13', 'isbn10']\n",
      "[meta] using ID column: 'isbn13'\n",
      "[ok] topics joined on item_id\n",
      "[ready] rows=3507, text_cols=['title', 'description', 'authors', 'categories']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>volume_id</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>description</th>\n",
       "      <th>categories</th>\n",
       "      <th>publishedDate</th>\n",
       "      <th>pageCount</th>\n",
       "      <th>language</th>\n",
       "      <th>averageRating</th>\n",
       "      <th>ratingsCount</th>\n",
       "      <th>previewLink</th>\n",
       "      <th>infoLink</th>\n",
       "      <th>item_id</th>\n",
       "      <th>isbn10</th>\n",
       "      <th>dominant_topic</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>machine learning</td>\n",
       "      <td>u8OWDwAAQBAJ</td>\n",
       "      <td>An Introduction to Machine Learning</td>\n",
       "      <td>Gopinath Rebala, Ajay Ravi, Sanjay Churiwala</td>\n",
       "      <td>Just like electricity, Machine Learning will r...</td>\n",
       "      <td>Technology &amp; Engineering</td>\n",
       "      <td>2019-05-07</td>\n",
       "      <td>275.0</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://books.google.co.uk/books?id=u8OWDwAAQBA...</td>\n",
       "      <td>https://play.google.com/store/books/details?id...</td>\n",
       "      <td>9.783030e+12</td>\n",
       "      <td>3030157296</td>\n",
       "      <td>NaN</td>\n",
       "      <td>an introduction to machine learning just like ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>machine learning</td>\n",
       "      <td>i8hQhp1a62UC</td>\n",
       "      <td>Encyclopedia of Machine Learning</td>\n",
       "      <td>Claude Sammut, Geoffrey I. Webb</td>\n",
       "      <td>This comprehensive encyclopedia, in A-Z format...</td>\n",
       "      <td>Computers</td>\n",
       "      <td>2011-03-28</td>\n",
       "      <td>1061.0</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://books.google.co.uk/books?id=i8hQhp1a62U...</td>\n",
       "      <td>http://books.google.co.uk/books?id=i8hQhp1a62U...</td>\n",
       "      <td>9.780387e+12</td>\n",
       "      <td>0387307680</td>\n",
       "      <td>NaN</td>\n",
       "      <td>encyclopedia of machine learning this comprehe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            keyword     volume_id                                title  \\\n",
       "0  machine learning  u8OWDwAAQBAJ  An Introduction to Machine Learning   \n",
       "1  machine learning  i8hQhp1a62UC     Encyclopedia of Machine Learning   \n",
       "\n",
       "                                        authors  \\\n",
       "0  Gopinath Rebala, Ajay Ravi, Sanjay Churiwala   \n",
       "1               Claude Sammut, Geoffrey I. Webb   \n",
       "\n",
       "                                         description  \\\n",
       "0  Just like electricity, Machine Learning will r...   \n",
       "1  This comprehensive encyclopedia, in A-Z format...   \n",
       "\n",
       "                 categories publishedDate  pageCount language  averageRating  \\\n",
       "0  Technology & Engineering    2019-05-07      275.0       en            NaN   \n",
       "1                 Computers    2011-03-28     1061.0       en            NaN   \n",
       "\n",
       "   ratingsCount                                        previewLink  \\\n",
       "0           NaN  http://books.google.co.uk/books?id=u8OWDwAAQBA...   \n",
       "1           NaN  http://books.google.co.uk/books?id=i8hQhp1a62U...   \n",
       "\n",
       "                                            infoLink       item_id  \\\n",
       "0  https://play.google.com/store/books/details?id...  9.783030e+12   \n",
       "1  http://books.google.co.uk/books?id=i8hQhp1a62U...  9.780387e+12   \n",
       "\n",
       "       isbn10  dominant_topic  \\\n",
       "0  3030157296             NaN   \n",
       "1  0387307680             NaN   \n",
       "\n",
       "                                                text  \n",
       "0  an introduction to machine learning just like ...  \n",
       "1  encyclopedia of machine learning this comprehe...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# 1) Load metadata\n",
    "META_PATH = Path(\"..\")/\"..\" / \"backend\" / \"data\" / \"interim\" / \"books_metadata.csv\"\n",
    "meta = pd.read_csv(META_PATH)\n",
    "\n",
    "print(\"[meta] rows:\", len(meta))\n",
    "print(\"[meta] columns:\", list(meta.columns))\n",
    "\n",
    "# 2) Flexible ID picker (case-insensitive, supports common variants)\n",
    "def pick_id_flexible(df: pd.DataFrame):\n",
    "    cols = [c for c in df.columns if isinstance(c, str)]\n",
    "    lut = {c.lower(): c for c in cols}\n",
    "\n",
    "    # exact matches first (in priority order)\n",
    "    for key in [\"item_id\",\"external_id\",\"global_id\",\"id\",\"book_id\",\"isbn\",\"isbn13\",\"isbn_13\"]:\n",
    "        if key in lut:\n",
    "            return lut[key]\n",
    "\n",
    "    # substring matches next\n",
    "    for c in cols:\n",
    "        lc = c.lower()\n",
    "        if any(tok in lc for tok in [\"itemid\",\"externalid\",\"globalid\",\"bookid\",\"isbn\",\"asin\",\"doi\"]):\n",
    "            return c\n",
    "\n",
    "    # as a last resort: a unique URL column\n",
    "    for c in cols:\n",
    "        if c.lower() in {\"url\",\"link\"} and df[c].nunique() == len(df):\n",
    "            return c\n",
    "\n",
    "    return None\n",
    "\n",
    "id_col = pick_id_flexible(meta)\n",
    "\n",
    "if id_col:\n",
    "    print(f\"[meta] using ID column: {id_col!r}\")\n",
    "    meta = meta.rename(columns={id_col: \"item_id\"})\n",
    "else:\n",
    "    print(\"[warn] No obvious ID column in metadata â€” we'll continue WITHOUT topics and create a temporary item_id.\")\n",
    "    meta = meta.reset_index().rename(columns={\"index\":\"item_id\"})\n",
    "\n",
    "# 3) (Optional) Try to join topics ONLY if we have a real item_id\n",
    "K = 10\n",
    "df = meta.copy()  # start from metadata; recommender works with this alone\n",
    "\n",
    "if id_col:\n",
    "    try:\n",
    "        TOPICS_PATH = Path(\"csv\") / f\"books_dom_topics_K{K}_CLEAN.csv\"\n",
    "        dom = pd.read_csv(TOPICS_PATH)\n",
    "\n",
    "        # pick ID in topics file\n",
    "        def pick_id_topics(df):\n",
    "            for c in [\"item_id\",\"external_id\",\"global_id\",\"id\",\"book_id\",\"isbn\",\"isbn13\",\"isbn_13\"]:\n",
    "                if c in df.columns: return c\n",
    "            return None\n",
    "\n",
    "        dom_id = pick_id_topics(dom)\n",
    "        if dom_id:\n",
    "            dom = dom.rename(columns={dom_id: \"item_id\"})\n",
    "            # normalize dominant_topic name if needed\n",
    "            if \"dominant_topic\" not in dom.columns:\n",
    "                for alt in [\"dom_topic\",\"topic\",\"topic_id\"]:\n",
    "                    if alt in dom.columns:\n",
    "                        dom = dom.rename(columns={alt:\"dominant_topic\"})\n",
    "                        break\n",
    "            df = df.merge(dom[[\"item_id\",\"dominant_topic\"]], on=\"item_id\", how=\"left\")\n",
    "            print(\"[ok] topics joined on item_id\")\n",
    "        else:\n",
    "            print(\"[info] Could not find an ID column in topics CSV; skipping topics join.\")\n",
    "    except Exception as e:\n",
    "        print(\"[info] Skipping topics join:\", e)\n",
    "\n",
    "# 4) Build a clean text field from whatever text columns exist\n",
    "TEXT_CANDIDATES = [\"title\",\"description\",\"summary\",\"subtitle\",\"authors\",\"categories\",\"tags\"]\n",
    "TEXT_COLS = [c for c in TEXT_CANDIDATES if c in df.columns]\n",
    "assert TEXT_COLS, \"No usable text columns; need one of title/description/summary/subtitle/authors/categories/tags.\"\n",
    "\n",
    "def clean(s):\n",
    "    s = re.sub(r\"http\\S+|www\\.\\S+\", \" \", str(s).lower())\n",
    "    return \" \".join(s.split())\n",
    "\n",
    "df[\"text\"] = df[TEXT_COLS].astype(str).agg(\" \".join, axis=1).map(clean)\n",
    "\n",
    "print(f\"[ready] rows={len(df)}, text_cols={TEXT_COLS}\")\n",
    "df.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1b9f2cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[metric] Title-Echo@3 = 0.720 on n=50\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>categories</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.781098e+12</td>\n",
       "      <td>Natural Language Processing with Transformers,...</td>\n",
       "      <td>Lewis Tunstall, Leandro von Werra, Thomas Wolf</td>\n",
       "      <td>Computers</td>\n",
       "      <td>0.189424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.781492e+12</td>\n",
       "      <td>Practical Natural Language Processing</td>\n",
       "      <td>Sowmya Vajjala, Bodhisattwa Majumder, Anuj Gup...</td>\n",
       "      <td>Computers</td>\n",
       "      <td>0.182670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.781098e+12</td>\n",
       "      <td>Natural Language Processing with Transformers</td>\n",
       "      <td>Lewis Tunstall, Leandro von Werra, Thomas Wolf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.179438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.781803e+12</td>\n",
       "      <td>Transformers for Natural Language Processing</td>\n",
       "      <td>Denis Rothman</td>\n",
       "      <td>Computers</td>\n",
       "      <td>0.178685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.789820e+12</td>\n",
       "      <td>Natural Language Processing</td>\n",
       "      <td>Raymond Lee</td>\n",
       "      <td>Computers</td>\n",
       "      <td>0.176154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9.781839e+12</td>\n",
       "      <td>Hands-On Python Natural Language Processing</td>\n",
       "      <td>Aman Kedia, Mayank Rasu</td>\n",
       "      <td>Computers</td>\n",
       "      <td>0.146739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9.781638e+12</td>\n",
       "      <td>Transfer Learning for Natural Language Processing</td>\n",
       "      <td>Paul Azunre</td>\n",
       "      <td>Computers</td>\n",
       "      <td>0.138830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9.781638e+12</td>\n",
       "      <td>Real-World Natural Language Processing</td>\n",
       "      <td>Masato Hagiwara</td>\n",
       "      <td>Computers</td>\n",
       "      <td>0.130691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.783032e+12</td>\n",
       "      <td>Handbook on Natural Language Processing for Re...</td>\n",
       "      <td>Alessio Ferrari, Gouri Ginde</td>\n",
       "      <td>Computers</td>\n",
       "      <td>0.125995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.789820e+12</td>\n",
       "      <td>Natural Language Processing</td>\n",
       "      <td>Raymond S. T. Lee</td>\n",
       "      <td>Computers</td>\n",
       "      <td>0.121881</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        item_id                                              title  \\\n",
       "0  9.781098e+12  Natural Language Processing with Transformers,...   \n",
       "1  9.781492e+12              Practical Natural Language Processing   \n",
       "2  9.781098e+12      Natural Language Processing with Transformers   \n",
       "3  9.781803e+12       Transformers for Natural Language Processing   \n",
       "4  9.789820e+12                        Natural Language Processing   \n",
       "5  9.781839e+12        Hands-On Python Natural Language Processing   \n",
       "6  9.781638e+12  Transfer Learning for Natural Language Processing   \n",
       "7  9.781638e+12             Real-World Natural Language Processing   \n",
       "8  9.783032e+12  Handbook on Natural Language Processing for Re...   \n",
       "9  9.789820e+12                        Natural Language Processing   \n",
       "\n",
       "                                             authors categories  similarity  \n",
       "0     Lewis Tunstall, Leandro von Werra, Thomas Wolf  Computers    0.189424  \n",
       "1  Sowmya Vajjala, Bodhisattwa Majumder, Anuj Gup...  Computers    0.182670  \n",
       "2     Lewis Tunstall, Leandro von Werra, Thomas Wolf        NaN    0.179438  \n",
       "3                                      Denis Rothman  Computers    0.178685  \n",
       "4                                        Raymond Lee  Computers    0.176154  \n",
       "5                            Aman Kedia, Mayank Rasu  Computers    0.146739  \n",
       "6                                        Paul Azunre  Computers    0.138830  \n",
       "7                                    Masato Hagiwara  Computers    0.130691  \n",
       "8                       Alessio Ferrari, Gouri Ginde  Computers    0.125995  \n",
       "9                                  Raymond S. T. Lee  Computers    0.121881  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ===  TF-IDF recommender + sanity check (using .toarray().ravel()) ===\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import normalize\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Build TF-IDF index\n",
    "tfidf = TfidfVectorizer(min_df=2, max_df=0.9, ngram_range=(1,2))\n",
    "X = tfidf.fit_transform(df[\"text\"])\n",
    "X = normalize(X)\n",
    "\n",
    "def recommend_books(query: str, k: int = 10):\n",
    "    qv = normalize(tfidf.transform([clean(query)]))\n",
    "    sims = (qv @ X.T).toarray().ravel()  # <- Option 2: dense vector\n",
    "    idx = np.argsort(-sims)[:k]\n",
    "    cols = [\"item_id\"] + [c for c in [\"title\",\"authors\",\"categories\",\"level\",\"url\"] if c in df.columns]\n",
    "    out = df.iloc[idx][cols].copy()\n",
    "    out[\"similarity\"] = sims[idx]\n",
    "    return out.reset_index(drop=True)\n",
    "\n",
    "# Title-Echo@3 sanity check\n",
    "def title_echo_at3(sample=50, seed=42):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    n = min(sample, len(df))\n",
    "    idxs = rng.choice(len(df), size=n, replace=False)\n",
    "    titles = df[\"title\"] if \"title\" in df.columns else df[\"text\"].str.slice(0,120)\n",
    "    hits = 0\n",
    "    for i in idxs:\n",
    "        qv = normalize(tfidf.transform([clean(str(titles.iloc[i]))]))\n",
    "        sims = (qv @ X.T).toarray().ravel()  # <- Option 2 here as well\n",
    "        top3 = np.argpartition(-sims, 2)[:3]\n",
    "        hits += int(i in top3)\n",
    "    rate = hits / n\n",
    "    print(f\"[metric] Title-Echo@3 = {rate:.3f} on n={n}\")\n",
    "    return rate\n",
    "\n",
    "# Run sanity + sample query\n",
    "title_echo_at3()\n",
    "recommend_books(\"transformers and attention for nlp\", k=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ab6ce16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ILD@10: 0.777\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def intra_list_diversity_from_query(query: str, k: int = 10) -> float:\n",
    "    qv = normalize(tfidf.transform([clean(query)]))\n",
    "    sims = (qv @ X.T).toarray().ravel()\n",
    "    idx = np.argsort(-sims)[:k]\n",
    "    Xk = X[idx]                         # normalized TF-IDF rows for top-K\n",
    "    S = (Xk @ Xk.T).toarray()           # cosine similarity matrix\n",
    "    iu = np.triu_indices(k, 1)\n",
    "    return 1.0 - float(S[iu].mean()) if k > 1 else 0.0\n",
    "\n",
    "# example usage:\n",
    "print(\"ILD@10:\", round(intra_list_diversity_from_query(\"transformers and attention for nlp\", k=10), 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4420be1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
