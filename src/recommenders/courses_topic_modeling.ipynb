{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e8e322c",
   "metadata": {},
   "source": [
    "topic modeling and assigned each course a dominant_topic. As we already have text_for_embedding lowercased, stripped of punctuation/HTML, etc., we can directly use it into vectorizers without extra cleaning.  Using the same field for embeddings and topic modeling keeps consistency. Column \"text_for_embedding\" concatenates cleaned title and cleaned description (and possibly skills/tags). This gives a fuller representation of each course’s content. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b942f8f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded catalog: (1343, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>global_id</th>\n",
       "      <th>platform</th>\n",
       "      <th>title</th>\n",
       "      <th>provider</th>\n",
       "      <th>level</th>\n",
       "      <th>description</th>\n",
       "      <th>clean_title</th>\n",
       "      <th>clean_description</th>\n",
       "      <th>text_for_embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>edx_0</td>\n",
       "      <td>edx</td>\n",
       "      <td>How to Learn Online</td>\n",
       "      <td>edX</td>\n",
       "      <td>Beginner</td>\n",
       "      <td>Learn essential strategies for successful onli...</td>\n",
       "      <td>how to learn online</td>\n",
       "      <td>learn essential strategies for successful onli...</td>\n",
       "      <td>how to learn online learn essential strategies...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>edx_1</td>\n",
       "      <td>edx</td>\n",
       "      <td>Programming for Everybody (Getting Started wit...</td>\n",
       "      <td>The University of Michigan</td>\n",
       "      <td>Beginner</td>\n",
       "      <td>This course is a \"no prerequisite\" introductio...</td>\n",
       "      <td>programming for everybody getting started with...</td>\n",
       "      <td>this course is a no prerequisite introduction ...</td>\n",
       "      <td>programming for everybody getting started with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>edx_2</td>\n",
       "      <td>edx</td>\n",
       "      <td>CS50's Introduction to Computer Science</td>\n",
       "      <td>Harvard University</td>\n",
       "      <td>Beginner</td>\n",
       "      <td>An introduction to the intellectual enterprise...</td>\n",
       "      <td>cs50 s introduction to computer science</td>\n",
       "      <td>an introduction to the intellectual enterprise...</td>\n",
       "      <td>cs50 s introduction to computer science an int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>edx_3</td>\n",
       "      <td>edx</td>\n",
       "      <td>The Analytics Edge</td>\n",
       "      <td>Massachusetts Institute of Technology</td>\n",
       "      <td>Intermediate</td>\n",
       "      <td>Through inspiring examples and stories, discov...</td>\n",
       "      <td>the analytics edge</td>\n",
       "      <td>through inspiring examples and stories discove...</td>\n",
       "      <td>the analytics edge through inspiring examples ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>edx_4</td>\n",
       "      <td>edx</td>\n",
       "      <td>Marketing Analytics: Marketing Measurement Str...</td>\n",
       "      <td>University of California, Berkeley</td>\n",
       "      <td>Beginner</td>\n",
       "      <td>This course is part of a MicroMasters® Program...</td>\n",
       "      <td>marketing analytics marketing measurement stra...</td>\n",
       "      <td>this course is part of a micromasters program ...</td>\n",
       "      <td>marketing analytics marketing measurement stra...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  global_id platform                                              title  \\\n",
       "0     edx_0      edx                                How to Learn Online   \n",
       "1     edx_1      edx  Programming for Everybody (Getting Started wit...   \n",
       "2     edx_2      edx            CS50's Introduction to Computer Science   \n",
       "3     edx_3      edx                                 The Analytics Edge   \n",
       "4     edx_4      edx  Marketing Analytics: Marketing Measurement Str...   \n",
       "\n",
       "                                provider         level  \\\n",
       "0                                    edX      Beginner   \n",
       "1             The University of Michigan      Beginner   \n",
       "2                     Harvard University      Beginner   \n",
       "3  Massachusetts Institute of Technology  Intermediate   \n",
       "4     University of California, Berkeley      Beginner   \n",
       "\n",
       "                                         description  \\\n",
       "0  Learn essential strategies for successful onli...   \n",
       "1  This course is a \"no prerequisite\" introductio...   \n",
       "2  An introduction to the intellectual enterprise...   \n",
       "3  Through inspiring examples and stories, discov...   \n",
       "4  This course is part of a MicroMasters® Program...   \n",
       "\n",
       "                                         clean_title  \\\n",
       "0                                how to learn online   \n",
       "1  programming for everybody getting started with...   \n",
       "2            cs50 s introduction to computer science   \n",
       "3                                 the analytics edge   \n",
       "4  marketing analytics marketing measurement stra...   \n",
       "\n",
       "                                   clean_description  \\\n",
       "0  learn essential strategies for successful onli...   \n",
       "1  this course is a no prerequisite introduction ...   \n",
       "2  an introduction to the intellectual enterprise...   \n",
       "3  through inspiring examples and stories discove...   \n",
       "4  this course is part of a micromasters program ...   \n",
       "\n",
       "                                  text_for_embedding  \n",
       "0  how to learn online learn essential strategies...  \n",
       "1  programming for everybody getting started with...  \n",
       "2  cs50 s introduction to computer science an int...  \n",
       "3  the analytics edge through inspiring examples ...  \n",
       "4  marketing analytics marketing measurement stra...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import numpy as np\n",
    "\n",
    "#Load cleaned catalog\n",
    "process_dir = \"../data/processed\"\n",
    "catalog_path = os.path.join(process_dir, \"courses_combined_cleaned.csv\")\n",
    "\n",
    "df = pd.read_csv(catalog_path)\n",
    "print(\"Loaded catalog:\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8925f3e",
   "metadata": {},
   "source": [
    "1. LDA Topic Modeling on text_for_embedding\n",
    "Here using scikit-learn’s CountVectorizer + LatentDirichletAllocation ..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec93763e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document-term matrix shape: (1343, 232)\n"
     ]
    }
   ],
   "source": [
    "# 2. Vectorize texts with CountVectorizer, we can adjust min_df and max_df for specific dataset size. \n",
    "# 'clean_description' is used directly for topic modeling (use \"text_for_embedding\" to compare).\n",
    "\n",
    "\n",
    "if 'clean_title' not in df.columns:\n",
    "    raise KeyError(\"Column 'text_for_embedding' not found. Ensure your DataFrame has this column.\")\n",
    "\n",
    "texts = df['clean_title'].fillna(\"\").astype(str).tolist()\n",
    "\n",
    "n_features = 10000 # adjust accordingly based \n",
    "vectorizer = CountVectorizer(max_df=0.95, min_df=5, stop_words='english', max_features=n_features)\n",
    "dtm = vectorizer.fit_transform(texts)\n",
    "print(\"Document-term matrix shape:\", dtm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ddf29576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1 of max_iter: 10\n",
      "iteration: 2 of max_iter: 10\n",
      "iteration: 3 of max_iter: 10\n",
      "iteration: 4 of max_iter: 10\n",
      "iteration: 5 of max_iter: 10\n",
      "iteration: 6 of max_iter: 10\n",
      "iteration: 7 of max_iter: 10\n",
      "iteration: 8 of max_iter: 10\n",
      "iteration: 9 of max_iter: 10\n",
      "iteration: 10 of max_iter: 10\n",
      "Topic distributions shape: (1343, 30)\n"
     ]
    }
   ],
   "source": [
    "# Fit LDA\n",
    "\n",
    "n_topics = 30  # choose based on desired granularity\n",
    "lda = LatentDirichletAllocation(n_components=n_topics,\n",
    "                                max_iter=10,\n",
    "                                learning_method='batch',\n",
    "                                random_state=0,\n",
    "                                verbose=1)\n",
    "topic_distributions = lda.fit_transform(dtm)  # shape: (n_docs, n_topics)\n",
    "print(\"Topic distributions shape:\", topic_distributions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51c39b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign dominant topic and full distributions\n",
    "dominant_topics = np.argmax(topic_distributions, axis=1)\n",
    "df['dominant_topic'] = dominant_topics\n",
    "# Optionally store the full distribution in separate columns:\n",
    "for topic_idx in range(n_topics):\n",
    "    df[f\"topic_{topic_idx}\"] = topic_distributions[:, topic_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "824b04c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top words per topic:\n",
      "Topic 0: fundamentals, iot, things, internet, neuroscience, political, networks, microsoft, customer, cybersecurity\n",
      "Topic 1: learning, machine, operations, deep, music, tensorflow, risk, economics, production, healthcare\n",
      "Topic 2: english, advanced, ap, writing, learn, scientific, sales, literature, real, intermediate\n",
      "Topic 3: ibm, methods, applications, developer, meta, end, research, basic, analyst, javascript\n",
      "Topic 4: foundations, design, marketing, user, ux, analytics, technology, process, product, approach\n",
      "Topic 5: cybersecurity, finance, systems, accounting, decentralized, modeling, banking, investment, future, infrastructure\n",
      "Topic 6: engineering, essentials, entrepreneurship, sql, materials, databases, urban, customer, artificial, coding\n",
      "Topic 7: digital, fintech, cloud, aws, professional, markets, emerging, people, marketing, devops\n",
      "Topic 8: introduction, blockchain, services, supply, global, chain, psychology, culture, financial, sigma\n",
      "Topic 9: computer, creating, essential, science, course, dynamics, inference, modeling, principles, modern\n",
      "Topic 10: security, china, training, market, preparation, leader, global, exam, risks, operations\n",
      "Topic 11: financial, technology, leadership, strategy, management, strategic, concepts, healthcare, risks, industry\n",
      "Topic 12: leading, chinese, biology, information, teams, models, innovation, mandarin, level, systems\n",
      "Topic 13: skills, agile, life, calculus, communication, principles, program, process, effective, leadership\n",
      "Topic 14: world, tools, visualization, modern, medicine, code, digital, microsoft, literature, linux\n",
      "Topic 15: public, intelligence, scriptures, analyst, approach, bi, health, business, international, writing\n",
      "Topic 16: started, getting, power, economy, circular, automation, sustainable, bi, cloud, exam\n",
      "Topic 17: ai, making, decision, networks, applied, generative, future, product, javascript, neural\n",
      "Topic 18: health, energy, nutrition, managing, master, effective, leader, culture, mechanics, principles\n",
      "Topic 19: business, english, transformation, en, japanese, ol, espa, intermediate, level, preparation\n",
      "Topic 20: analytics, data, law, change, statistical, big, excel, health, technologies, care\n",
      "Topic 21: python, thinking, statistics, structures, data, algorithms, problem, computing, mathematics, innovation\n",
      "Topic 22: human, linear, understanding, algebra, rights, teaching, using, art, models, electric\n",
      "Topic 23: analysis, programming, python, financial, policy, policies, basics, linux, success, program\n",
      "Topic 24: cloud, google, infrastructure, computing, capstone, core, native, overview, applications, en\n",
      "Topic 25: language, processing, networking, practical, natural, science, models, change, using, culture\n",
      "Topic 26: management, project, java, theory, google, programming, planning, modeling, real, capstone\n",
      "Topic 27: data, science, python, sql, azure, microsoft, using, applied, exam, real\n",
      "Topic 28: social, work, media, network, probability, justice, practice, mathtrackx, statistics, marketing\n",
      "Topic 29: development, cloud, sustainable, software, basics, engineer, certification, preparing, google, food\n"
     ]
    }
   ],
   "source": [
    "# Inspect top words per topic\n",
    "\n",
    "def print_top_words(model, feature_names, n_top_words=10):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        top_features_ind = topic.argsort()[:-n_top_words - 1:-1]\n",
    "        top_features = [feature_names[i] for i in top_features_ind]\n",
    "        print(f\"Topic {topic_idx}: {', '.join(top_features)}\")\n",
    "\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "print(\"Top words per topic:\")\n",
    "print_top_words(lda, feature_names, n_top_words=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad421db2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
