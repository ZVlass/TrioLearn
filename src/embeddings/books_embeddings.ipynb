{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a68ad2b5",
   "metadata": {},
   "source": [
    "Embedding Book Metadata with all-MiniLM-L6-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "468fa78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "471b4f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"..\")  # Go up to project root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5f953ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_books = pd.read_csv(\"C:/Users/jvlas/source/repos/TrioLearn/data/interim/books_metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72aba505",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jvlas\\AppData\\Local\\Temp\\ipykernel_54612\\1538531904.py:2: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df_books.fillna(\"\", inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Fill missing fields (avoid errors during string joining)\n",
    "df_books.fillna(\"\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d03a1124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine text fields into one string for embedding\n",
    "df_books[\"text_for_embedding\"] = (\n",
    "    df_books[\"title\"] + \" \" +\n",
    "    df_books[\"description\"] + \" \" +\n",
    "    df_books[\"categories\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d183baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jvlas\\source\\repos\\TrioLearn\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading .gitattributes: 1.23kB [00:00, 615kB/s]\n",
      "Downloading config.json: 100%|██████████| 190/190 [00:00<00:00, 189kB/s]\n",
      "Downloading README.md: 10.5kB [00:00, 10.3MB/s]\n",
      "Downloading config.json: 100%|██████████| 612/612 [00:00<?, ?B/s] \n",
      "Downloading (…)ce_transformers.json: 100%|██████████| 116/116 [00:00<00:00, 76.6kB/s]\n",
      "Downloading data_config.json: 39.3kB [00:00, 19.5MB/s]\n",
      "Downloading model.safetensors: 100%|██████████| 90.9M/90.9M [00:02<00:00, 39.0MB/s]\n",
      "Downloading model.onnx: 100%|██████████| 90.4M/90.4M [00:01<00:00, 51.6MB/s]\n",
      "Downloading model_O1.onnx: 100%|██████████| 90.4M/90.4M [00:01<00:00, 54.0MB/s]\n",
      "Downloading model_O2.onnx: 100%|██████████| 90.3M/90.3M [00:01<00:00, 54.0MB/s]\n",
      "Downloading model_O3.onnx: 100%|██████████| 90.3M/90.3M [00:01<00:00, 53.5MB/s]\n",
      "Downloading model_O4.onnx: 100%|██████████| 45.2M/45.2M [00:00<00:00, 56.7MB/s]\n",
      "Downloading model_qint8_arm64.onnx: 100%|██████████| 23.0M/23.0M [00:00<00:00, 52.4MB/s]\n",
      "Downloading model_qint8_arm64.onnx: 100%|██████████| 23.0M/23.0M [00:00<00:00, 56.0MB/s]\n",
      "Downloading model_qint8_arm64.onnx: 100%|██████████| 23.0M/23.0M [00:00<00:00, 54.0MB/s]\n",
      "Downloading model_quint8_avx2.onnx: 100%|██████████| 23.0M/23.0M [00:00<00:00, 54.9MB/s]\n",
      "Downloading openvino_model.bin: 100%|██████████| 90.3M/90.3M [00:01<00:00, 54.2MB/s]\n",
      "Downloading openvino_model.xml: 211kB [00:00, 28.7MB/s]\n",
      "Downloading (…)_qint8_quantized.bin: 100%|██████████| 22.9M/22.9M [00:00<00:00, 43.9MB/s]\n",
      "Downloading (…)_qint8_quantized.xml: 368kB [00:00, 121MB/s]\n",
      "Downloading pytorch_model.bin: 100%|██████████| 90.9M/90.9M [00:02<00:00, 41.9MB/s]\n",
      "Downloading (…)nce_bert_config.json: 100%|██████████| 53.0/53.0 [00:00<00:00, 52.5kB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 112/112 [00:00<00:00, 112kB/s]\n",
      "Downloading tokenizer.json: 466kB [00:00, 12.2MB/s]\n",
      "Downloading tokenizer_config.json: 100%|██████████| 350/350 [00:00<00:00, 350kB/s]\n",
      "Downloading train_script.py: 13.2kB [00:00, 13.0MB/s]\n",
      "Downloading vocab.txt: 232kB [00:00, 21.9MB/s]\n",
      "Downloading modules.json: 100%|██████████| 349/349 [00:00<?, ?B/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Model loaded\n"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained Sentence-BERT model\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "print(\" Model loaded\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "052101da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.34s/it]\n"
     ]
    }
   ],
   "source": [
    "#  Compute embeddings (batch process for performance)\n",
    "embeddings = model.encode(df_books[\"text_for_embedding\"].tolist(), show_progress_bar=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7b42d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store as separate columns\n",
    "embedding_df = pd.DataFrame(embeddings, columns=[f\"emb_{i}\" for i in range(embeddings.shape[1])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a1ea54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate with original metadata\n",
    "df_books_embedded = pd.concat([df_books, embedding_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df13d250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 20 books with embeddings to: data\\processed\\books_with_embeddings.csv\n"
     ]
    }
   ],
   "source": [
    "processed_dir = os.path.join(\"data\", \"processed\")\n",
    "os.makedirs(processed_dir, exist_ok=True)\n",
    "\n",
    "save_path = os.path.join(processed_dir, \"books_with_embeddings.csv\")\n",
    "df_books_embedded.to_csv(save_path, index=False)\n",
    "\n",
    "print(f\"Saved {len(df_books_embedded)} books with embeddings to:\", save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55112ce5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
